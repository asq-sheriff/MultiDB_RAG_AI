---
title: AI Architecture - Actual Implementation
owner: AI Engineering Team
last_updated: 2025-09-04
status: authoritative
---

# AI Architecture - Actual Implementation

> **Real-world AI service orchestration for therapeutic healthcare conversations**

## Current System Overview

The therapeutic AI system is implemented as a hybrid architecture with Python AI services and Go microservices, designed for senior care with safety-first principles and HIPAA compliance.

### System Architecture Status
**Current Implementation**: Python AI Gateway (8000) + Go Microservices + Host Services + Hybrid Data Layer  
**AI Gateway**: `ai_services/main.py` - FastAPI orchestration service  
**Core Services**: 10 specialized AI modules in `ai_services/core/`  
**Host Services**: 2 GPU-accelerated services (`host_services/`)  
**Go Microservices**: 8 services handling auth, billing, safety, audit  
**Performance**: 77-99% faster with confidence-based cascading search

```mermaid
flowchart TB
    subgraph "API Layer"
        API_GW[üåê Go API Gateway<br/>Port 8090<br/>Primary Entry Point]
        AI_GW[ü§ñ Python AI Gateway<br/>Port 8000<br/>AI Orchestration]
    end
    
    subgraph "AI Services (Python)"
        CB_SVC[üí¨ ChatbotService<br/>Main conversation handler]
        KS_SVC[üìö KnowledgeService<br/>RAG pipeline controller<br/>Confidence-based cascading]
        URC_SVC[üéØ UserContextRouter<br/>Role-based data routing]
        ARS_SVC[üìä AdvancedRankingService<br/>Multi-signal ranking]
        IDR_SVC[üß≠ IntelligentDataRouter<br/>Multi-DB query routing]
        TCM_SVC[‚ö° TherapeuticCacheManager<br/>HIPAA-compliant caching]
        SCS_SVC[üîç SemanticConversationSearch<br/>History search w/ embeddings]
        CES_SVC[üéØ CrossEncoderService<br/>ms-marco-MiniLM-L-12-v2]
        CE_SVC[üî¨ ConfidenceEvaluator<br/>Search confidence analysis]
        MDB_SVC[üîó MultiDBService<br/>Cross-DB coordination]
    end
    
    subgraph "Host Services (GPU)"
        EMBED_HOST[üß† BGE Embedding Server<br/>Port 8008<br/>BAAI/bge-large-en-v1.5]
        GEN_HOST[ü§ñ Qwen Generation Server<br/>Port 8007<br/>qwen2.5-7b-instruct]
    end
    
    subgraph "Go Microservices"
        AUTH_SVC[üîê Auth/RBAC<br/>Port 8080]
        SAFETY_SVC[üõ°Ô∏è Content Safety<br/>Port 8007<br/>PHI + Crisis Detection]
        CHAT_SVC[üí≠ Chat History<br/>Port 8002<br/>ScyllaDB]
        AUDIT_SVC[üìã Audit Logging<br/>Port 8084]
        CONSENT_SVC[‚úÖ Consent<br/>Port 8083]
        BILLING_SVC[üí∞ Billing<br/>Port 8081]
    end
    
    subgraph "Database Layer"
        PG[(üêò PostgreSQL<br/>5 Schemas: auth,<br/>compliance, app,<br/>memory, knowledge)]
        MONGO[(üçÉ MongoDB<br/>Document store,<br/>therapeutic_content)]
        REDIS[(üöÄ Redis<br/>Cache, sessions,<br/>rate limiting)]
        SCYLLA[(‚ö° ScyllaDB<br/>Conversation history,<br/>analytics)]
    end
    
    %% API Flow
    API_GW --> AUTH_SVC
    API_GW --> AI_GW
    
    %% AI Service Orchestration
    AI_GW --> CB_SVC
    CB_SVC --> KS_SVC
    CB_SVC --> URC_SVC
    CB_SVC --> MDB_SVC
    KS_SVC --> CE_SVC
    KS_SVC --> ARS_SVC
    KS_SVC --> IDR_SVC
    KS_SVC --> TCM_SVC
    URC_SVC --> SCS_SVC
    ARS_SVC --> CES_SVC
    
    %% Host Service Integration
    KS_SVC --> EMBED_HOST
    CB_SVC --> GEN_HOST
    
    %% Go Microservice Integration
    AI_GW --> SAFETY_SVC
    AI_GW --> CHAT_SVC
    API_GW --> AUDIT_SVC
    API_GW --> CONSENT_SVC
    API_GW --> BILLING_SVC
    
    %% Database Connections
    URC_SVC --> PG
    KS_SVC --> MONGO
    TCM_SVC --> REDIS
    CHAT_SVC --> SCYLLA
    AUTH_SVC --> PG
    AUDIT_SVC --> PG
    CONSENT_SVC --> PG
    
    classDef python fill:#3776ab,color:#fff
    classDef golang fill:#00add8,color:#fff
    classDef database fill:#f8f8f8,stroke:#333
    classDef api fill:#4caf50,color:#fff
    
    class CB_SVC,KS_SVC,URC_SVC,ARS_SVC,IDR_SVC,TCM_SVC,SCS_SVC,CES_SVC,CE_SVC,MDB_SVC python
    class EMBED_HOST,GEN_HOST python
    class AUTH_SVC,SAFETY_SVC,CHAT_SVC,AUDIT_SVC,CONSENT_SVC,BILLING_SVC golang
    class PG,MONGO,REDIS,SCYLLA database
    class API_GW,AI_GW api
```

## Core AI Services Implementation

### 1. ChatbotService (`ai_services/core/chatbot_service.py`)
**Purpose**: Main conversation orchestrator and RAG pipeline coordinator  
**Key Features**:
- Enhanced RAG pipeline with user context integration
- Crisis detection and safety filtering
- Multi-database context assembly
- Real-time response generation with Qwen2.5-7B

```python
class EnhancedChatbotService:
    """Main therapeutic conversation handler"""
    
    async def chat(self, message: str, user_context: dict) -> ChatResponse:
        # 1. User context routing with PostgreSQL data
        # 2. Knowledge retrieval via KnowledgeService
        # 3. Advanced ranking and re-ranking
        # 4. Response generation with context injection
        # 5. Safety validation and empathy enhancement
```

### 2. KnowledgeService (`ai_services/core/knowledge_service.py`)
**Purpose**: Unified knowledge retrieval with MongoDB Atlas Vector Search  
**Key Features**:
- Semantic search with BGE-large-en-v1.5 embeddings
- Text search with MongoDB $text queries
- Cross-encoder re-ranking with ms-marco-MiniLM-L-12-v2
- User context filtering (post-MongoDB query)

```python
class KnowledgeService:
    """Unified knowledge retrieval service"""
    
    async def search_router(self, query: str, filters: dict) -> SearchResults:
        # 1. Query embedding generation
        # 2. MongoDB semantic + text search
        # 3. User context post-processing filter
        # 4. Advanced ranking with cross-encoder
        # 5. Top-k selection with quality scoring
```

### 3. UserContextRouter (`ai_services/core/user_context_router.py`)
**Purpose**: Role-based data routing and intent classification  
**Key Features**:
- Healthcare role detection (care_physician, care_staff, resident, family_member)
- Intent classification (resident_management, wellness_alerts, dashboard_data)
- PostgreSQL user data integration
- Semantic pattern matching with regex

```python
class UserContextRouter:
    """Routes queries based on user role and intent"""
    
    async def route_user_context_query(self, context: QueryContext) -> UserData:
        # 1. Intent classification via semantic patterns
        # 2. PostgreSQL user data retrieval
        # 3. Role-specific data formatting
        # 4. Context-aware response enhancement
```

### 4. AdvancedRankingService (`ai_services/core/advanced_ranking_service.py`)
**Purpose**: Multi-signal ranking with variance reduction  
**Key Features**:
- Cross-encoder re-ranking (ms-marco-MiniLM-L-12-v2)
- Adaptive ranking strategy selection
- Score normalization and variance reduction
- Reciprocal Rank Fusion (RRF) support

```python
class AdvancedRankingService:
    """Advanced ranking with cross-encoder"""
    
    async def rank_results(self, query: str, results: List) -> RankedResults:
        # 1. Strategy selection (adaptive/hybrid/RRF)
        # 2. Cross-encoder scoring with MiniLM
        # 3. Score normalization and variance reduction
        # 4. Quality improvement measurement
```

### 5. IntelligentDataRouter (`ai_services/core/intelligent_data_router.py`)
**Purpose**: Multi-database query routing optimization  
**Key Features**:
- Query type classification (document_search, user_auth, therapeutic_context)
- Database-specific routing (MongoDB for documents, PostgreSQL for users)
- Performance tracking and optimization
- Therapeutic context awareness

```python
class IntelligentTherapeuticRouter:
    """Routes queries to optimal databases"""
    
    async def route_query(self, query: str, context: dict) -> RoutedResults:
        # 1. Query type classification
        # 2. Database selection optimization
        # 3. Parallel query execution
        # 4. Result fusion and caching
```

### 6. TherapeuticCacheManager (`ai_services/core/therapeutic_cache_manager.py`)
**Purpose**: Multi-tier caching with HIPAA compliance  
**Key Features**:
- L1 (Memory) + L2 (MongoDB) + L3 (Persistent) caching
- PHI detection and cache exclusion
- Semantic clustering for cache warming
- Rate limiting with token bucket algorithm

```python
class TherapeuticCacheManager:
    """HIPAA-compliant multi-tier caching"""
    
    async def get_cached_response(self, cache_key: str) -> CachedResponse:
        # 1. L1 memory cache check
        # 2. L2 MongoDB cache check
        # 3. L3 persistent cache check
        # 4. PHI detection and exclusion
        # 5. Semantic cluster cache warming
```

### 7. SemanticConversationSearch (`ai_services/core/semantic_conversation_search.py`)
**Purpose**: Semantic search across conversation history  
**Key Features**:
- Query embedding storage in PostgreSQL
- Conversation history retrieval from ScyllaDB
- Semantic similarity search with cosine distance
- Query metrics and search quality tracking

```python
class SemanticConversationSearch:
    """Search past conversations semantically"""
    
    async def find_similar_conversations(self, query: str) -> ConversationMatches:
        # 1. Query embedding storage in PostgreSQL
        # 2. Semantic similarity search
        # 3. ScyllaDB conversation context retrieval
        # 4. Match scoring and ranking
```

### 8. CrossEncoderService (`ai_services/core/cross_encoder_service.py`)
**Purpose**: Advanced re-ranking with transformer models  
**Key Features**:
- ms-marco-MiniLM-L-12-v2 model loading
- GPU acceleration with MPS/CUDA support
- Batch processing optimization
- Advanced score normalization

```python
class CrossEncoderService:
    """Transformer-based re-ranking"""
    
    async def rerank_results(self, query: str, passages: List) -> RankedResults:
        # 1. Model loading with GPU acceleration
        # 2. Batch inference optimization
        # 3. Score normalization with advanced techniques
        # 4. Quality measurement and validation
```

### 9. ConfidenceEvaluator (`ai_services/core/confidence_evaluator.py`) 
**Purpose**: Confidence-based search strategy optimization for 77-99% performance improvement  
**Key Features**:
- Real-time text search quality evaluation (1-5ms)
- Medical terminology coverage assessment (diabetes, medication, therapy)
- Therapeutic context relevance scoring (emotions, daily living, social)
- Healthcare-specific confidence thresholds (high: >0.7, medium: 0.4-0.7, low: <0.4)
- Cascading search strategy selection

```python
class ConfidenceEvaluator:
    """Evaluates confidence in text search results for cascading strategy"""
    
    def evaluate_text_results(self, query: str, results: List) -> ConfidenceScore:
        # 1. Text match quality assessment (exact + partial word matches)
        # 2. Medical terminology coverage analysis (5 categories)
        # 3. Therapeutic context relevance scoring (4 categories)  
        # 4. Overall confidence computation with healthcare weights
        
    def should_cascade_to_vector(self, confidence: ConfidenceScore) -> str:
        # Returns: 'text_only' (high confidence), 'hybrid' (medium), 'vector_only' (low)
        # Achieves 50-2300ms ‚Üí 2-527ms performance improvement
```

## Data Flow Architecture

### Enhanced RAG Pipeline with Confidence-Based Cascading
```mermaid
sequenceDiagram
    participant User
    participant AI_GW as AI Gateway
    participant CB as ChatbotService
    participant URC as UserContextRouter
    participant KS as KnowledgeService
    participant CE as ConfidenceEvaluator
    participant ARS as AdvancedRankingService
    participant EMBED as BGE Host (8008)
    participant GEN as Qwen Host (8007)
    participant PG as PostgreSQL
    participant MONGO as MongoDB
    
    User->>AI_GW: User query + context
    AI_GW->>CB: Process conversation
    CB->>URC: Extract user context
    URC->>PG: Query user data by role
    PG-->>URC: User-specific data
    
    Note over KS,CE: Confidence-Based Cascading Search (77-99% faster)
    CB->>KS: Search knowledge base
    KS->>MONGO: Fast text search (10-50ms)
    MONGO-->>KS: Text search results
    KS->>CE: Evaluate confidence
    CE-->>KS: Strategy: text_only|hybrid|vector_only
    
    alt High Confidence (text_only)
        KS-->>CB: Return text results (50ms total)
    else Medium Confidence (hybrid)
        KS->>EMBED: Generate query embedding
        EMBED-->>KS: 1024-dim BGE embedding
        KS->>MONGO: Combine text + vector search
        MONGO-->>KS: Enhanced results
        KS->>ARS: Re-rank with cross-encoder
        ARS-->>KS: Ranked results (400-600ms total)
    else Low Confidence (vector_only)
        KS->>EMBED: Generate query embedding
        EMBED-->>KS: 1024-dim BGE embedding
        KS->>MONGO: Vector search only
        MONGO-->>KS: Vector results
        KS->>ARS: Re-rank results
        ARS-->>KS: Ranked results (200-300ms total)
    end
    
    KS-->>CB: Enhanced context
    CB->>GEN: Generate therapeutic response
    GEN-->>CB: Qwen2.5-7B response
    CB-->>AI_GW: Complete response
    AI_GW-->>User: Therapeutic response
```

## Database Schema Integration

### PostgreSQL Schemas (5 Total)
1. **auth**: User authentication and roles
2. **compliance**: HIPAA audit trails and consent
3. **app**: Application data and sessions
4. **memory**: Query embeddings and conversation analytics
5. **knowledge**: Healthcare knowledge base (secondary to MongoDB)

### MongoDB Collections
1. **therapeutic_content**: Main knowledge base with BGE embeddings
2. **documents**: Raw document storage
3. **therapeutic_response_cache**: L2 cache storage

### Redis Data Structures
1. **Cache keys**: `therapeutic:cache:{hash}` - L1 cache persistence
2. **Rate limit buckets**: `rate_limit:{user_id}` - Token bucket state
3. **Session data**: `session:{session_id}` - User session context

### ScyllaDB Tables
1. **conversation_history**: Time-series conversation storage
2. **conversation_analytics**: Performance metrics and usage data

### 10. MultiDBService (`ai_services/core/multi_db_service.py`)
**Purpose**: Simplified cross-database data coordination service
**Key Features**:
- Conversation storage coordination (Redis sessions + ScyllaDB history)
- Cache invalidation across tiers
- Data consistency for therapeutic sessions
- Performance analytics and monitoring
- Redis/ScyllaDB-only operations (no auth/billing)

```python
class MultiDatabaseService:
    """Coordinates data operations across Redis and ScyllaDB only"""
    
    async def store_conversation(self, session_id: str, user_message: str, bot_response: str):
        # 1. Store in ScyllaDB conversation history
        # 2. Update Redis session data
        # 3. Cache invalidation coordination
        # 4. Analytics event tracking
```

## Host Services Layer (GPU-Accelerated)

### 11. BGE Embedding Server (`host_services/embed_server.py`)
**Purpose**: BAAI/bge-large-en-v1.5 embedding generation with Metal GPU acceleration
**Key Features**:
- **Port 8008** - FastAPI server for host GPU access
- **Metal/MPS GPU acceleration** for Apple Silicon M1/M2/M3
- **1024-dimensional embeddings** - Production-grade vector representations
- **Query prefix handling** - "Represent this sentence for searching relevant passages"
- **Batch processing optimization** - Multiple text inputs per request
- **Real-time embedding** for both queries and documents

```python
# BGE Embedding Server Endpoints
POST /embed_query - Single query embedding generation
POST /embed - Batch embedding generation (OpenAI compatible)
GET /health - Service health check
GET /model_info - BGE model information
```

### 12. Qwen Generation Server (`host_services/generation_server.py`)  
**Purpose**: qwen2.5-7b-instruct therapeutic AI generation with llama.cpp optimization
**Key Features**:
- **Port 8007** - FastAPI server for host GPU access  
- **llama.cpp backend** - Optimized C++ inference for performance
- **OpenAI-compatible API** - `/v1/chat/completions` endpoint
- **Therapeutic conversation specialization** - Senior care focused responses
- **Context-aware response generation** - RAG context integration
- **Safety-filtered output validation** - Crisis detection integration

```python
# Qwen Generation Server Endpoints  
POST /v1/chat/completions - OpenAI compatible chat completion
POST /generate - Simple generation endpoint
GET /health - Service health check with model status
GET /model_info - Qwen model configuration
```

## Performance Characteristics

### Response Time Targets (Achieved with Confidence-Based Cascading)
- **High Confidence Queries**: 2-50ms (text-only strategy)
- **Medium Confidence Queries**: 400-600ms (hybrid strategy)  
- **Low Confidence Queries**: 200-300ms (vector-only strategy)
- **Cache Hit**: <50ms for L1, <200ms for L2
- **BGE Embedding Generation**: 20-100ms per query
- **Qwen Response Generation**: 500-2000ms depending on context length
- **Cross-encoder Re-ranking**: 300-800ms for 5-10 documents

### Scalability Metrics
- **Concurrent Users**: 100+ with current architecture
- **Cache Efficiency**: 85%+ hit rate with warming
- **Database Performance**: <10ms PostgreSQL, <50ms MongoDB
- **Memory Usage**: ~4GB for AI models, 2GB for caching

## Configuration and Environment

### Critical Environment Variables
```bash
# AI Model Configuration
USE_REAL_EMBEDDINGS=1
USE_REAL_GENERATION=1
EMBEDDING_MODEL=BAAI/bge-large-en-v1.5
GENERATION_MODEL=qwen2.5-7b-instruct

# Database Configuration
ENABLE_POSTGRESQL=true
ENABLE_MONGODB=true
MONGO_HOST=localhost
MONGO_PORT=27018  # Demo: 27018, Production: 27017

# Caching Configuration
CACHE_TTL=3600
THERAPEUTIC_CACHE_ENABLED=true
RATE_LIMIT_ENABLED=true

# HIPAA Compliance
HIPAA_AUDIT_LEVEL=strict
PHI_DETECTION_ENABLED=true
CONSENT_MANAGEMENT_ENABLED=true
```

## Deployment Architecture

### Service Dependencies
```
Go API Gateway (8090) - Primary Entry Point
‚îú‚îÄ‚îÄ Python AI Gateway (8000) - AI Orchestration Hub
‚îÇ   ‚îú‚îÄ‚îÄ ChatbotService - Main conversation handler
‚îÇ   ‚îú‚îÄ‚îÄ KnowledgeService - RAG pipeline with confidence cascading
‚îÇ   ‚îú‚îÄ‚îÄ UserContextRouter - Role-based data routing
‚îÇ   ‚îú‚îÄ‚îÄ AdvancedRankingService - Multi-signal ranking
‚îÇ   ‚îú‚îÄ‚îÄ IntelligentDataRouter - Multi-DB query routing
‚îÇ   ‚îú‚îÄ‚îÄ TherapeuticCacheManager - HIPAA-compliant caching
‚îÇ   ‚îú‚îÄ‚îÄ SemanticConversationSearch - Conversation history search
‚îÇ   ‚îú‚îÄ‚îÄ CrossEncoderService - Transformer-based re-ranking
‚îÇ   ‚îú‚îÄ‚îÄ ConfidenceEvaluator - Search strategy optimization
‚îÇ   ‚îî‚îÄ‚îÄ MultiDBService - Cross-database coordination
‚îú‚îÄ‚îÄ BGE Embedding Host (8008) - GPU-accelerated embeddings
‚îú‚îÄ‚îÄ Qwen Generation Host (8007) - GPU-accelerated generation
‚îú‚îÄ‚îÄ Go Auth/RBAC (8080) - Authentication & authorization
‚îú‚îÄ‚îÄ Go Content Safety (8007) - PHI + crisis detection
‚îú‚îÄ‚îÄ Go Chat History (8002) - ScyllaDB conversation storage
‚îú‚îÄ‚îÄ Go Audit Logging (8084) - HIPAA compliance logging
‚îú‚îÄ‚îÄ Go Consent Management (8083) - Privacy controls
‚îî‚îÄ‚îÄ Go Billing Service (8081) - Usage tracking
```

### Health Monitoring
```python
# Health check endpoints
GET /health - Basic service status
GET /health/detailed - Full dependency check
GET /health/ai - AI model status
GET /health/cache - Cache performance metrics
GET /health/databases - Database connection status
```

## Security and Compliance

### HIPAA Technical Safeguards (¬ß164.312)
- **Access Control**: Role-based access with PostgreSQL auth schema
- **Audit Controls**: Comprehensive logging via Go audit service
- **Integrity**: PHI detection and masking in Content Safety service
- **Person/Entity Authentication**: Multi-factor auth for healthcare providers
- **Transmission Security**: TLS encryption for all service communication

### PHI Protection Pipeline
```mermaid
flowchart LR
    INPUT[User Input] --> PHI_SCAN[PHI Detection]
    PHI_SCAN -->|PHI Detected| MASK[PHI Masking]
    PHI_SCAN -->|Clean| PROCESS[AI Processing]
    MASK --> AUDIT[Audit Logging]
    PROCESS --> OUTPUT[Response]
    AUDIT --> OUTPUT
```

## Monitoring and Observability

### Key Metrics
- **AI Response Quality**: Average 4.2/5.0 therapeutic quality
- **Cache Performance**: 85%+ hit rate across all tiers
- **Crisis Detection**: <1s response time for safety escalation
- **Database Performance**: 95%+ queries under SLA targets
- **HIPAA Compliance**: 100% audit trail coverage

### Alerting Thresholds
- **Response Time**: >3s for complex queries
- **Error Rate**: >5% for any service
- **Cache Miss Rate**: >30% indicates warming issues
- **PHI Exposure**: Any detected PHI triggers immediate alert
- **Crisis Detection**: All crisis events trigger care team notification

---

**AI Architecture Version**: 3.0 (Actual Implementation)  
**Last Updated**: 2025-09-04  
**Next Review**: 2025-10-01  
**Maintained By**: AI Engineering Team + Clinical Advisory Board